{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7068,
     "status": "ok",
     "timestamp": 1630505480342,
     "user": {
      "displayName": "Maksim STW",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxlsxJPsP-vnUHqOGVOd2IwzlsoHIBvoM27xTB=s64",
      "userId": "15228803154242880172"
     },
     "user_tz": 240
    },
    "id": "LPrt3Gw6siZn"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import csv\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "transformers.logging.set_verbosity(transformers.logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model: distilbert-base-uncased-finetuned-sst-2-english\n"
     ]
    }
   ],
   "source": [
    "model_name = 'distilbert'\n",
    "\n",
    "cols = ['history', 'history_aave', 'sae_gen', 'aave_gen']\n",
    "\n",
    "if model_name == 'distilbert':\n",
    "    model = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "elif model_name == 'roberta_base':\n",
    "    model = 'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "elif model_name == 'roberta_large':\n",
    "    model = 'siebert/sentiment-roberta-large-english'\n",
    "else:\n",
    "    raise Exception('MODEL NOT FOUND!!!')\n",
    "\n",
    "print(f'using model: {model}')\n",
    "classifier = pipeline('sentiment-analysis', device=0, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'runs/13/dialogpt/dailydialog_all.csv'\n",
    "output_path = 'runs/13/dialogpt/sentiment/dailydialog_sentiment.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model: distilbert-base-uncased-finetuned-sst-2-english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5181/5181 [01:15<00:00, 68.83it/s]\n",
      "100%|██████████| 5181/5181 [02:41<00:00, 32.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model: cardiffnlp/twitter-roberta-base-sentiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5181/5181 [02:24<00:00, 35.79it/s]\n",
      "100%|██████████| 5181/5181 [04:46<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model: siebert/sentiment-roberta-large-english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5181/5181 [04:17<00:00, 20.11it/s]\n",
      "100%|██████████| 5181/5181 [08:32<00:00, 10.11it/s]\n"
     ]
    }
   ],
   "source": [
    "cols = ['history', 'history_aave', 'sae_gen', 'aave_gen']\n",
    "for model_name in ['distilbert', 'roberta_base', 'roberta_large']:\n",
    "    if model_name == 'distilbert':\n",
    "        model = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "    elif model_name == 'roberta_base':\n",
    "        model = 'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "    elif model_name == 'roberta_large':\n",
    "        model = 'siebert/sentiment-roberta-large-english'\n",
    "    else:\n",
    "        raise Exception('MODEL NOT FOUND!!!')\n",
    "    print(f'using model: {model}')\n",
    "    classifier = pipeline('sentiment-analysis', device=0, model=model)\n",
    "    analyze_gt()\n",
    "    analyze_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_gt():\n",
    "    f = open(output_path[:-4] + '_' + model_name + '_gt.csv', 'a', encoding='utf-8')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['groundtruth', 'groundtruth_aave'])\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    for i in tqdm(range(len(df))):\n",
    "        row = df.iloc[i]\n",
    "        scores = []\n",
    "        for col in ['groundtruth', 'groundtruth_aave']:\n",
    "            text = row[col]\n",
    "            if text != text:\n",
    "                text = \" \"\n",
    "            if len(text) > 510:\n",
    "                text = text[:510]\n",
    "            score = classifier(text)\n",
    "            scores.append(score[0]['label'])\n",
    "        writer.writerow(scores)\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all():\n",
    "    f = open(output_path[:-4] + '_' + model_name + '.csv', 'a', encoding='utf-8')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(cols)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    for i in tqdm(range(len(df))):\n",
    "        row = df.iloc[i]\n",
    "        scores = []\n",
    "        for col in cols:\n",
    "            text = row[col]\n",
    "            if text != text:\n",
    "                text = \" \"\n",
    "            if len(text) > 510:\n",
    "                text = text[:510]\n",
    "            score = classifier(text)\n",
    "            scores.append(score[0]['label'])\n",
    "        writer.writerow(scores)\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta_large, groundtruth\n",
      "NEGATIVE    7357\n",
      "POSITIVE    3264\n",
      "Name: groundtruth, dtype: int64\n",
      "roberta_large, groundtruth_aave\n",
      "NEGATIVE    7393\n",
      "POSITIVE    3228\n",
      "Name: groundtruth_aave, dtype: int64\n",
      "roberta_base, groundtruth\n",
      "LABEL_0    2895\n",
      "LABEL_1    6772\n",
      "LABEL_2     954\n",
      "Name: groundtruth, dtype: int64\n",
      "roberta_base, groundtruth_aave\n",
      "LABEL_0    3000\n",
      "LABEL_1    6620\n",
      "LABEL_2    1001\n",
      "Name: groundtruth_aave, dtype: int64\n",
      "distilbert, groundtruth\n",
      "NEGATIVE    8191\n",
      "POSITIVE    2430\n",
      "Name: groundtruth, dtype: int64\n",
      "distilbert, groundtruth_aave\n",
      "NEGATIVE    8116\n",
      "POSITIVE    2505\n",
      "Name: groundtruth_aave, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "f = open('runs/13/dialogpt/stats/cornell_movie_gt_stats.csv', 'w', encoding='utf-8', newline='')\n",
    "writer = csv.writer(f)\n",
    "for m in ['roberta_large', 'roberta_base', 'distilbert']:\n",
    "    for col in ['groundtruth', 'groundtruth_aave']:\n",
    "        df = pd.read_csv(f'runs/13/dialogpt/sentiment/cornell_movie_sentiment_{m}_gt.csv')\n",
    "        print(f'{m}, {col}')\n",
    "        print(df[col].value_counts().sort_index())\n",
    "        writer.writerow([m, col])\n",
    "        writer.writerow(df[col].value_counts().sort_index())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta_large, aave_gen\n",
      "NEGATIVE    5448\n",
      "POSITIVE    4314\n",
      "Name: aave_gen, dtype: int64\n",
      "roberta_large, sae_gen\n",
      "NEGATIVE    5416\n",
      "POSITIVE    4346\n",
      "Name: sae_gen, dtype: int64\n",
      "roberta_base, aave_gen\n",
      "LABEL_0    2717\n",
      "LABEL_1    3718\n",
      "LABEL_2    3327\n",
      "Name: aave_gen, dtype: int64\n",
      "roberta_base, sae_gen\n",
      "LABEL_0    2742\n",
      "LABEL_1    3687\n",
      "LABEL_2    3333\n",
      "Name: sae_gen, dtype: int64\n",
      "distilbert, aave_gen\n",
      "NEGATIVE    4472\n",
      "POSITIVE    5290\n",
      "Name: aave_gen, dtype: int64\n",
      "distilbert, sae_gen\n",
      "NEGATIVE    4418\n",
      "POSITIVE    5344\n",
      "Name: sae_gen, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "f = open('runs/13/dialogpt/stats/cornell_movie_stats.csv', 'w', encoding='utf-8', newline='')\n",
    "writer = csv.writer(f)\n",
    "for m in ['roberta_large', 'roberta_base', 'distilbert']:\n",
    "    for d in ['aave_gen', 'sae_gen']:\n",
    "        df = pd.read_csv(f'runs/13/bst/sentiment/cornell_movie_sentiment_{m}.csv')\n",
    "        print(f'{m}, {d}')\n",
    "        print(df[d].value_counts().sort_index())\n",
    "        writer.writerow([m, d])\n",
    "        writer.writerow(df[d].value_counts().sort_index())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('stats.csv', 'w', encoding='utf-8', newline='')\n",
    "for d in dialects:\n",
    "    for col in ['prompt', 'truth', 'generation']:\n",
    "        df = pd.read_csv('runs/09 casino/' + model_name + '/' + d + '_' + col + '_sentimental_analysis.csv', header=None)\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print(f'{model_name}, {d}, {col}')\n",
    "        print(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "referenced_widgets": [
      "7e586e8dda6c465ebdd51b0d2433d51f",
      "231e2839a05f4a6593ec4c5d88e8a788",
      "80785cc1ab5e4a4a8e6ae01cfd8be7d7",
      "83f2f483822a4354ba913dd96ca8be2c",
      "fa3b9a40dc9943a18a838c6c0e546e89",
      "96494ddfd9aa4f9eb7f8f9823d382fe3",
      "fca3a2fbff874386ae0e35b4efa3a922",
      "d9ecb8eb875a45978569b34eef0c3da6",
      "91c7ea6883d84937ada56f387fb98cbd",
      "fc3029839bb640f0a4198a5c0beabd8e",
      "de3a5ace7bad4963954ad0b9088a4149"
     ]
    },
    "executionInfo": {
     "elapsed": 13386,
     "status": "ok",
     "timestamp": 1630509135963,
     "user": {
      "displayName": "Maksim STW",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxlsxJPsP-vnUHqOGVOd2IwzlsoHIBvoM27xTB=s64",
      "userId": "15228803154242880172"
     },
     "user_tz": 240
    },
    "id": "NzWG90yM2cf6",
    "outputId": "e0730a07-eba3-461d-d375-5c3a5bfed820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.1 using roberta_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [00:18<00:00, 26.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.1 using roberta_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 487/487 [00:16<00:00, 29.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.5 using roberta_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [00:16<00:00, 29.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.5 using roberta_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 487/487 [00:15<00:00, 30.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.7 using roberta_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [00:15<00:00, 31.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.7 using roberta_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 487/487 [00:15<00:00, 30.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.0 using roberta_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [00:15<00:00, 30.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.0 using roberta_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 487/487 [00:15<00:00, 30.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.2 using roberta_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [00:15<00:00, 30.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.2 using roberta_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 487/487 [00:16<00:00, 29.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.5 using roberta_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [00:16<00:00, 29.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.5 using roberta_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 487/487 [00:16<00:00, 29.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 2.0 using roberta_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [00:16<00:00, 30.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 2.0 using roberta_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 487/487 [00:16<00:00, 29.80it/s]\n"
     ]
    }
   ],
   "source": [
    "for t in temp:\n",
    "    for d in dialects:\n",
    "        print(f'starting analyzation on dialect: {d}, temperature: {t} using {model_name}')\n",
    "        df = pd.read_csv('runs/' + output_path +'/Generation/1_feature/temp=' + str(t) + '_' + str(d) + '_gen_txt.csv')\n",
    "        with open('runs/' + output_path + '/Sentiment Analysis/1_feature/' + model_name + '/temp=' + str(t) + '_' + str(d) + '_sentiment.csv', 'a', encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['prompt', 'truth', 'generation'])\n",
    "            for i in tqdm(range(df.shape[0])):\n",
    "                prompt = classifier(df.iloc[i]['prompt'])\n",
    "                truth = classifier(df.iloc[i]['truth'])\n",
    "                generation = classifier(df.iloc[i]['generation'])\n",
    "                writer.writerow([prompt[0]['label'], truth[0]['label'], generation[0]['label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# function to print sentiments\n",
    "# of the sentence.\n",
    "def sentiment_scores(sentence):\n",
    " \n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    # object gives a sentiment dictionary.\n",
    "    # which contains pos, neg, neu, and compound scores.\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    " \n",
    "    # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        return \"Positive\"\n",
    " \n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        return \"Negative\"\n",
    " \n",
    "    else :\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Analysis on Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [0.1, 0.5, 0.7, 1.0, 1.2, 1.5]\n",
    "dialects = ['sae', 'aave']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 137.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 140.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 138.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 139.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 141.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 136.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 142.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 136.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 137.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 140.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 434/434 [00:03<00:00, 142.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 420/420 [00:03<00:00, 136.71it/s]\n"
     ]
    }
   ],
   "source": [
    "for t in temp:\n",
    "    for d in dialects:\n",
    "        print(f'starting analyzation on dialect: {d}, temperature: {t}')\n",
    "        df = pd.read_csv('runs/' + output_path +'/Generation/temp=' + str(t) + '/' + d + '_gen_txt.csv')\n",
    "        with open('runs/' + output_path +'/VADER/temp=' + str(t) + '/' + d + '_gen_txt_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for i, txt in enumerate(tqdm(df.gen)):\n",
    "                results = sentiment_scores(txt)\n",
    "                writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Analysis on Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sae; prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 137.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sae; prompt_cont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 139.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aave; prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 134.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aave; prompt_cont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 127.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for d in ['sae', 'aave']:\n",
    "    for col in ['prompt', 'prompt_cont']:\n",
    "        print(f'{d}; {col}')\n",
    "        df = pd.read_csv('runs/' + output_path +'/Generation/temp=0.1/' + d + '_gen_txt.csv')\n",
    "        with open('runs/' + output_path +'/VADER/' + d + '_' + col + '_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for i, txt in enumerate(tqdm(df[col])):\n",
    "                results = sentiment_scores(txt[2:-2])\n",
    "                writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"runs/03 EMNLP SAE-AAVE Pairs/sae_samples.tsv\", sep=\"\\t\")\n",
    "# with open('runs/03 EMNLP SAE-AAVE Pairs/VADER/sae_second_seg_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     for i, txt in enumerate(tq.tqdm(df.second_seg)):\n",
    "#         results = sentiment_scores(txt)\n",
    "#         writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER, sae, prompt\n",
      "Negative     78\n",
      "Neutral     299\n",
      "Positive    115\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "VADER, sae, prompt_cont\n",
      "Negative    103\n",
      "Neutral     294\n",
      "Positive     95\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "VADER, aave, prompt\n",
      "Negative     77\n",
      "Neutral     300\n",
      "Positive    115\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "VADER, aave, prompt_cont\n",
      "Negative     97\n",
      "Neutral     296\n",
      "Positive     99\n",
      "Name: 1, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('stats.csv', 'w', encoding='utf-8', newline='')\n",
    "for d in dialects:\n",
    "    for col in ['prompt', 'prompt_cont']:\n",
    "        df = pd.read_csv('runs/' + output_path +'/VADER/' + d + '_' + col + '_sentimental_analysis.csv', header=None)\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print(f'VADER, {d}, {col}')\n",
    "        print(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: VADER; generation: sae; temperature 0.1\n",
      "Negative     62\n",
      "Neutral     341\n",
      "Positive     89\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: aave; temperature 0.1\n",
      "Negative     80\n",
      "Neutral     326\n",
      "Positive     86\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: sae; temperature 0.5\n",
      "Negative     45\n",
      "Neutral     358\n",
      "Positive     89\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: aave; temperature 0.5\n",
      "Negative     60\n",
      "Neutral     319\n",
      "Positive    113\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: sae; temperature 0.7\n",
      "Negative     59\n",
      "Neutral     335\n",
      "Positive     98\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: aave; temperature 0.7\n",
      "Negative     63\n",
      "Neutral     322\n",
      "Positive    107\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: sae; temperature 1.0\n",
      "Negative     48\n",
      "Neutral     337\n",
      "Positive    107\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: aave; temperature 1.0\n",
      "Negative     70\n",
      "Neutral     327\n",
      "Positive     95\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: sae; temperature 1.2\n",
      "Negative     53\n",
      "Neutral     334\n",
      "Positive    105\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: aave; temperature 1.2\n",
      "Negative     61\n",
      "Neutral     328\n",
      "Positive    103\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: sae; temperature 1.5\n",
      "Negative     48\n",
      "Neutral     299\n",
      "Positive     87\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: aave; temperature 1.5\n",
      "Negative     58\n",
      "Neutral     275\n",
      "Positive     87\n",
      "Name: 1, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('stats.csv', 'w', encoding='utf-8', newline='')\n",
    "for t in temp:\n",
    "    for d in dialects:\n",
    "        df = pd.read_csv('runs/' + output_path +'/VADER/temp=' + str(t) + '/' + str(d) + '_gen_txt_sentimental_analysis.csv', header=None)\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print(f'model: VADER; generation: {d}; temperature {t}')\n",
    "        print(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run Text Blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Blob Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def textblob_score(sentence):\n",
    "    result = TextBlob(sentence)\n",
    "    if result.sentiment.polarity == 0:\n",
    "        return \"Neutral\"\n",
    "    elif result.sentiment.polarity > 0:\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [0.1, 0.5, 0.7, 1.0, 1.2, 1.5]\n",
    "dialects = ['sae', 'aave']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Analysis on Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 4729.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8198.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8337.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8198.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8337.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8337.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8337.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8337.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8480.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8337.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 434/434 [00:00<00:00, 8344.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 420/420 [00:00<00:00, 7922.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for t in temp:\n",
    "    for d in dialects:\n",
    "        print(f'starting analyzation on dialect: {d}, temperature: {t}')\n",
    "        df = pd.read_csv('runs/' + output_path +'/Generation/temp=' + str(t) + '/' + d + '_gen_txt.csv')\n",
    "        with open('runs/' + output_path +'/TextBlob/temp=' + str(t) + '/' + d + '_gen_txt_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for i, txt in enumerate(tqdm(df.gen)):\n",
    "                results = textblob_score(txt)\n",
    "                writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Analysis on Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob, sae; prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 7026.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob, sae; prompt_cont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 7807.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob, aave; prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 7567.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob, aave; prompt_cont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 7567.70it/s]\n"
     ]
    }
   ],
   "source": [
    "for d in ['sae', 'aave']:\n",
    "    for col in ['prompt', 'prompt_cont']:\n",
    "        print(f'TextBlob, {d}; {col}')\n",
    "        df = pd.read_csv('runs/' + output_path +'/Generation/temp=0.1/' + d + '_gen_txt.csv')\n",
    "        with open('runs/' + output_path +'/TextBlob/' + d + '_' + col + '_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for i, txt in enumerate(tqdm(df[col])):\n",
    "                results = textblob_score(txt[2:-2])\n",
    "                writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob Gen, sae, prompt\n",
      "Negative     57\n",
      "Neutral     306\n",
      "Positive    129\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "TextBlob Gen, sae, prompt_cont\n",
      "Negative     67\n",
      "Neutral     309\n",
      "Positive    116\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "TextBlob Gen, aave, prompt\n",
      "Negative     55\n",
      "Neutral     318\n",
      "Positive    119\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "TextBlob Gen, aave, prompt_cont\n",
      "Negative     49\n",
      "Neutral     324\n",
      "Positive    119\n",
      "Name: 1, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('stats.csv', 'w', encoding='utf-8', newline='')\n",
    "for d in ['sae', 'aave']:\n",
    "    for col in ['prompt', 'prompt_cont']:\n",
    "        df = pd.read_csv('runs/' + output_path +'/TextBlob/' + d + '_' + col + '_sentimental_analysis.csv', header=None)\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print(f'TextBlob Gen, {d}, {col}')\n",
    "        print(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: TextBlob; generation: sae; temperature 0.1\n",
      "Negative     59\n",
      "Neutral     345\n",
      "Positive     88\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: aave; temperature 0.1\n",
      "Negative     67\n",
      "Neutral     314\n",
      "Positive    111\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: sae; temperature 0.5\n",
      "Negative     48\n",
      "Neutral     329\n",
      "Positive    115\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: aave; temperature 0.5\n",
      "Negative     63\n",
      "Neutral     312\n",
      "Positive    117\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: sae; temperature 0.7\n",
      "Negative     56\n",
      "Neutral     325\n",
      "Positive    111\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: aave; temperature 0.7\n",
      "Negative     48\n",
      "Neutral     320\n",
      "Positive    124\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: sae; temperature 1.0\n",
      "Negative     56\n",
      "Neutral     331\n",
      "Positive    105\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: aave; temperature 1.0\n",
      "Negative     52\n",
      "Neutral     314\n",
      "Positive    126\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: sae; temperature 1.2\n",
      "Negative     46\n",
      "Neutral     334\n",
      "Positive    112\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: aave; temperature 1.2\n",
      "Negative     50\n",
      "Neutral     317\n",
      "Positive    125\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: sae; temperature 1.5\n",
      "Negative     50\n",
      "Neutral     269\n",
      "Positive    115\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: aave; temperature 1.5\n",
      "Negative     44\n",
      "Neutral     281\n",
      "Positive     95\n",
      "Name: 1, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('stats.csv', 'w', encoding='utf-8', newline='')\n",
    "for t in temp:\n",
    "    for d in dialects:\n",
    "        print(f'model: TextBlob; generation: {d}; temperature {t}')\n",
    "        df = pd.read_csv('runs/' + output_path +'/TextBlob/temp=' + str(t) + '/' + str(d) + '_gen_txt_sentimental_analysis.csv', header=None)\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"runs/03 EMNLP SAE-AAVE Pairs/sae_gen_txt.csv\")\n",
    "# with open('runs/03 EMNLP SAE-AAVE Pairs/TextBlob/sae_gen_txt_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     for i, txt in enumerate(tq.tqdm(df.txt)):\n",
    "#         results = textblob_score(txt)\n",
    "#         writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPDmhOJdK8knUJB/yVl90hK",
   "collapsed_sections": [],
   "name": "BERT Dialect Classification.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "2e11e5a522e080512818b9bf84dbbd443475dd70c5375019780e8dfd28d97bce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('CS_4650_Proj': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "231e2839a05f4a6593ec4c5d88e8a788": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e586e8dda6c465ebdd51b0d2433d51f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_80785cc1ab5e4a4a8e6ae01cfd8be7d7",
       "IPY_MODEL_83f2f483822a4354ba913dd96ca8be2c",
       "IPY_MODEL_fa3b9a40dc9943a18a838c6c0e546e89"
      ],
      "layout": "IPY_MODEL_231e2839a05f4a6593ec4c5d88e8a788"
     }
    },
    "80785cc1ab5e4a4a8e6ae01cfd8be7d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fca3a2fbff874386ae0e35b4efa3a922",
      "placeholder": "​",
      "style": "IPY_MODEL_96494ddfd9aa4f9eb7f8f9823d382fe3",
      "value": "Downloading: 100%"
     }
    },
    "83f2f483822a4354ba913dd96ca8be2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91c7ea6883d84937ada56f387fb98cbd",
      "max": 435779157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d9ecb8eb875a45978569b34eef0c3da6",
      "value": 435779157
     }
    },
    "91c7ea6883d84937ada56f387fb98cbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96494ddfd9aa4f9eb7f8f9823d382fe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d9ecb8eb875a45978569b34eef0c3da6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "de3a5ace7bad4963954ad0b9088a4149": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa3b9a40dc9943a18a838c6c0e546e89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de3a5ace7bad4963954ad0b9088a4149",
      "placeholder": "​",
      "style": "IPY_MODEL_fc3029839bb640f0a4198a5c0beabd8e",
      "value": " 436M/436M [00:10&lt;00:00, 36.3MB/s]"
     }
    },
    "fc3029839bb640f0a4198a5c0beabd8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fca3a2fbff874386ae0e35b4efa3a922": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 7068,
     "status": "ok",
     "timestamp": 1630505480342,
     "user": {
      "displayName": "Maksim STW",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxlsxJPsP-vnUHqOGVOd2IwzlsoHIBvoM27xTB=s64",
      "userId": "15228803154242880172"
     },
     "user_tz": 240
    },
    "id": "LPrt3Gw6siZn"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import csv\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "transformers.logging.set_verbosity(transformers.logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "executionInfo": {
     "elapsed": 1130,
     "status": "ok",
     "timestamp": 1630505872351,
     "user": {
      "displayName": "Maksim STW",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxlsxJPsP-vnUHqOGVOd2IwzlsoHIBvoM27xTB=s64",
      "userId": "15228803154242880172"
     },
     "user_tz": 240
    },
    "id": "5PCzUqEitwuu",
    "outputId": "1e2c53e9-effb-4fdf-9b07-68690340ee00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_cont</th>\n",
       "      <th>gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>There are many farms crowding the area</td>\n",
       "      <td>, which all produce milk and pork.</td>\n",
       "      <td>, but the one in the center of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Her father kept bringing her various medical t...</td>\n",
       "      <td>and ain't nothing done ever worked.</td>\n",
       "      <td>, but she was always too weak to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>tin foil hat for the s</td>\n",
       "      <td>arg, what size u wear?</td>\n",
       "      <td>ultry night.\\r\\n\\r\\n\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The toaster Tom done bought</td>\n",
       "      <td>from him ain't work.</td>\n",
       "      <td>a new one.\\r\\n\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Where is it a very active tradition of hunting</td>\n",
       "      <td>of small to medium-sized wild game?</td>\n",
       "      <td>?\\r\\n\\r\\nI am not sure if I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                             prompt  \\\n",
       "0    0             There are many farms crowding the area   \n",
       "1    1  Her father kept bringing her various medical t...   \n",
       "2    3                             tin foil hat for the s   \n",
       "3    4                        The toaster Tom done bought   \n",
       "4    5     Where is it a very active tradition of hunting   \n",
       "\n",
       "                            prompt_cont                               gen  \n",
       "0    , which all produce milk and pork.    , but the one in the center of  \n",
       "1   and ain't nothing done ever worked.  , but she was always too weak to  \n",
       "2                arg, what size u wear?             ultry night.\\r\\n\\r\\n\"  \n",
       "3                  from him ain't work.                a new one.\\r\\n\\r\\n  \n",
       "4   of small to medium-sized wild game?       ?\\r\\n\\r\\nI am not sure if I  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"runs/06 Caleb Preprocessed/Generation/temp=0.1/aave_gen_txt.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1630505892012,
     "user": {
      "displayName": "Maksim STW",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxlsxJPsP-vnUHqOGVOd2IwzlsoHIBvoM27xTB=s64",
      "userId": "15228803154242880172"
     },
     "user_tz": 240
    },
    "id": "uUNlWdDkuSas",
    "outputId": "cf9eff8f-f32b-45f1-c0e8-b65353fec61d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1630505914076,
     "user": {
      "displayName": "Maksim STW",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxlsxJPsP-vnUHqOGVOd2IwzlsoHIBvoM27xTB=s64",
      "userId": "15228803154242880172"
     },
     "user_tz": 240
    },
    "id": "sisZi96-uWfH",
    "outputId": "d446049e-24b9-4777-a47c-12e2d9b194a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 492 entries, 0 to 491\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   idx          492 non-null    int64 \n",
      " 1   prompt       492 non-null    object\n",
      " 2   prompt_cont  492 non-null    object\n",
      " 3   gen          492 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 15.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsDaHpoXvwKK"
   },
   "source": [
    "## Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 22066,
     "status": "ok",
     "timestamp": 1630508634009,
     "user": {
      "displayName": "Maksim STW",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxlsxJPsP-vnUHqOGVOd2IwzlsoHIBvoM27xTB=s64",
      "userId": "15228803154242880172"
     },
     "user_tz": 240
    },
    "id": "KIC1yghzvlw7"
   },
   "outputs": [],
   "source": [
    "# PRE_TRAINED_MODEL_NAME = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "# classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, device=0)\n",
    "# classifier = pipeline('sentiment-analysis', device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model: siebert/sentiment-roberta-large-english\n"
     ]
    }
   ],
   "source": [
    "model_name = 'roberta'\n",
    "\n",
    "temp = [0.1, 0.5, 0.7, 1.0, 1.2, 1.5]\n",
    "dialects = ['sae', 'aave']\n",
    "\n",
    "if model_name == 'distilbert':\n",
    "    model = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "elif model_name == 'bert':\n",
    "    model = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "elif model_name == 'roberta':\n",
    "    model = 'siebert/sentiment-roberta-large-english'\n",
    "\n",
    "print(f'using model: {model}')\n",
    "classifier = pipeline('sentiment-analysis', device=0, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Analysis on Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "referenced_widgets": [
      "7e586e8dda6c465ebdd51b0d2433d51f",
      "231e2839a05f4a6593ec4c5d88e8a788",
      "80785cc1ab5e4a4a8e6ae01cfd8be7d7",
      "83f2f483822a4354ba913dd96ca8be2c",
      "fa3b9a40dc9943a18a838c6c0e546e89",
      "96494ddfd9aa4f9eb7f8f9823d382fe3",
      "fca3a2fbff874386ae0e35b4efa3a922",
      "d9ecb8eb875a45978569b34eef0c3da6",
      "91c7ea6883d84937ada56f387fb98cbd",
      "fc3029839bb640f0a4198a5c0beabd8e",
      "de3a5ace7bad4963954ad0b9088a4149"
     ]
    },
    "executionInfo": {
     "elapsed": 13386,
     "status": "ok",
     "timestamp": 1630509135963,
     "user": {
      "displayName": "Maksim STW",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxlsxJPsP-vnUHqOGVOd2IwzlsoHIBvoM27xTB=s64",
      "userId": "15228803154242880172"
     },
     "user_tz": 240
    },
    "id": "NzWG90yM2cf6",
    "outputId": "e0730a07-eba3-461d-d375-5c3a5bfed820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [00:08<00:00, 56.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [00:08<00:00, 56.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [00:08<00:00, 55.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [00:08<00:00, 54.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [00:08<00:00, 54.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [00:08<00:00, 55.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [00:08<00:00, 55.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [00:08<00:00, 54.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [00:09<00:00, 53.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [00:09<00:00, 53.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [00:09<00:00, 53.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 411/411 [00:07<00:00, 56.32it/s]\n"
     ]
    }
   ],
   "source": [
    "for t in temp:\n",
    "    for d in dialects:\n",
    "        print(f'starting analyzation on dialect: {d}, temperature: {t}')\n",
    "        df = pd.read_csv('runs/06 Caleb Preprocessed/Generation/temp=' + str(t) + '/' + str(d) + '_gen_txt.csv')\n",
    "        with open('runs/06 Caleb Preprocessed/' + model_name + '/temp=' + str(t) + '/' + str(d) + '_gen_txt_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for i, txt in enumerate(tqdm(df.gen)):\n",
    "                results = classifier(txt)\n",
    "                for result in results:\n",
    "                    writer.writerow([i, result['label'], round(result['score'], 4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Analysis on Orginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, column: prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [00:08<00:00, 56.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, column: prompt_cont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [00:08<00:00, 56.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, column: prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [00:08<00:00, 56.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, column: prompt_cont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [00:08<00:00, 56.77it/s]\n"
     ]
    }
   ],
   "source": [
    "for d in dialects:\n",
    "    for col in ['prompt', 'prompt_cont']:\n",
    "        print(f'starting analyzation on dialect: {d}, column: {col}')\n",
    "        df = pd.read_csv('runs/06 Caleb Preprocessed/Generation/temp=0.1/' + d + '_gen_txt.csv')\n",
    "        with open('runs/06 Caleb Preprocessed/' + model_name + '/' + d + '_' + col + '_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for i, txt in enumerate(tqdm(df[col])):\n",
    "                results = classifier(txt)\n",
    "                for result in results:\n",
    "                    writer.writerow([i, result['label'], round(result['score'], 4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sae, prompt\n",
      "NEGATIVE    238\n",
      "POSITIVE    254\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "sae, prompt_cont\n",
      "NEGATIVE    258\n",
      "POSITIVE    234\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "aave, prompt\n",
      "NEGATIVE    228\n",
      "POSITIVE    264\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "aave, prompt_cont\n",
      "NEGATIVE    254\n",
      "POSITIVE    238\n",
      "Name: 1, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in dialects:\n",
    "    for col in ['prompt', 'prompt_cont']:\n",
    "        df = pd.read_csv('runs/06 Caleb Preprocessed/' + model_name + '/' + d + '_' + col + '_sentimental_analysis.csv', header=None)\n",
    "        print(f'{model_name}, {d}, {col}')\n",
    "        print(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation: sae; temperature 0.1\n",
      "NEGATIVE    213\n",
      "POSITIVE    279\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "generation: aave; temperature 0.1\n",
      "NEGATIVE    213\n",
      "POSITIVE    279\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "generation: sae; temperature 0.5\n",
      "NEGATIVE    213\n",
      "POSITIVE    279\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "generation: aave; temperature 0.5\n",
      "NEGATIVE    214\n",
      "POSITIVE    278\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "generation: sae; temperature 0.7\n",
      "NEGATIVE    210\n",
      "POSITIVE    282\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "generation: aave; temperature 0.7\n",
      "NEGATIVE    206\n",
      "POSITIVE    286\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "generation: sae; temperature 1.0\n",
      "NEGATIVE    231\n",
      "POSITIVE    261\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "generation: aave; temperature 1.0\n",
      "NEGATIVE    227\n",
      "POSITIVE    265\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "generation: sae; temperature 1.2\n",
      "NEGATIVE    221\n",
      "POSITIVE    271\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "generation: aave; temperature 1.2\n",
      "NEGATIVE    219\n",
      "POSITIVE    273\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "generation: sae; temperature 1.5\n",
      "NEGATIVE    204\n",
      "POSITIVE    288\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "generation: aave; temperature 1.5\n",
      "NEGATIVE    186\n",
      "POSITIVE    225\n",
      "Name: 1, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in temp:\n",
    "    for d in dialects:\n",
    "        print(f'model: {model_name}; generation: {d}; temperature {t}')\n",
    "        sae_gen_pd = pd.read_csv('runs/06 Caleb Preprocessed/' + model_name + '/temp=' + str(t) + '/' + str(d) + '_gen_txt_sentimental_analysis.csv', header=None)\n",
    "        print(sae_gen_pd.iloc[:, 1].value_counts().sort_index())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# function to print sentiments\n",
    "# of the sentence.\n",
    "def sentiment_scores(sentence):\n",
    " \n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    # object gives a sentiment dictionary.\n",
    "    # which contains pos, neg, neu, and compound scores.\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    " \n",
    "    # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        return \"Positive\"\n",
    " \n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        return \"Negative\"\n",
    " \n",
    "    else :\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [0.1, 0.5, 0.7, 1.0, 1.2, 1.5]\n",
    "dialects = ['sae', 'aave']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:13<00:00, 52.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:13<00:00, 50.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:14<00:00, 49.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:13<00:00, 50.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:13<00:00, 50.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:13<00:00, 52.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:13<00:00, 52.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:13<00:00, 52.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:14<00:00, 48.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:14<00:00, 47.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:15<00:00, 46.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:15<00:00, 46.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for t in temp:\n",
    "    for d in dialects:\n",
    "        print(f'starting analyzation on dialect: {d}, temperature: {t}')\n",
    "        df = pd.read_csv('runs/05 Caleb/Generation/half/temp=' + str(t) + '/' + str(d) + '_gen_txt.csv')\n",
    "        with open('runs/05 Caleb/VADER/temp=' + str(t) + '/' + str(d) + '_gen_txt_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for i, txt in enumerate(tqdm(df.gen)):\n",
    "                results = sentiment_scores(txt[2:-2])\n",
    "                writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sae; prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:13<00:00, 51.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sae; prompt_cont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:13<00:00, 51.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aave; prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:13<00:00, 52.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aave; prompt_cont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 700/700 [00:13<00:00, 52.92it/s]\n"
     ]
    }
   ],
   "source": [
    "for d in ['sae', 'aave']:\n",
    "    for col in ['prompt', 'prompt_cont']:\n",
    "        print(f'{d}; {col}')\n",
    "        file_name = 'second' if col == 'prompt_cont' else 'first'\n",
    "        df = pd.read_csv('runs/05 Caleb/Generation/half/temp=0.1/' + str(d) + '_gen_txt.csv')\n",
    "        with open('runs/05 Caleb/VADER/' + d + '_' + file_name + '_seg_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for i, txt in enumerate(tqdm(df[col])):\n",
    "                results = sentiment_scores(txt[2:-2])\n",
    "                writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"runs/03 EMNLP SAE-AAVE Pairs/sae_samples.tsv\", sep=\"\\t\")\n",
    "# with open('runs/03 EMNLP SAE-AAVE Pairs/VADER/sae_second_seg_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     for i, txt in enumerate(tq.tqdm(df.second_seg)):\n",
    "#         results = sentiment_scores(txt)\n",
    "#         writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_first_pd = pd.read_csv(\"runs/05 Caleb/VADER/sae_first_seg_sentimental_analysis.csv\", header=None)\n",
    "sae_second_pd = pd.read_csv(\"runs/05 Caleb/VADER/sae_second_seg_sentimental_analysis.csv\", header=None)\n",
    "aave_first_pd = pd.read_csv(\"runs/05 Caleb/VADER/aave_first_seg_sentimental_analysis.csv\", header=None)\n",
    "aave_second_pd = pd.read_csv(\"runs/05 Caleb/VADER/aave_second_seg_sentimental_analysis.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE First Segment\n",
      "Negative    101\n",
      "Neutral     434\n",
      "Positive    165\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "SAE Second Segment\n",
      "Negative    146\n",
      "Neutral     392\n",
      "Positive    162\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "AAVE First Segment\n",
      "Negative    103\n",
      "Neutral     417\n",
      "Positive    180\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "AAVE Second Segment\n",
      "Negative    166\n",
      "Neutral     362\n",
      "Positive    172\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with sae and temperature 0.1\n",
      "Negative    109\n",
      "Neutral     459\n",
      "Positive    132\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with aave and temperature 0.1\n",
      "Negative    102\n",
      "Neutral     464\n",
      "Positive    134\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with sae and temperature 0.5\n",
      "Negative     85\n",
      "Neutral     454\n",
      "Positive    161\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with aave and temperature 0.5\n",
      "Negative     88\n",
      "Neutral     480\n",
      "Positive    132\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with sae and temperature 0.7\n",
      "Negative    110\n",
      "Neutral     439\n",
      "Positive    151\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with aave and temperature 0.7\n",
      "Negative     88\n",
      "Neutral     470\n",
      "Positive    142\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with sae and temperature 1.0\n",
      "Negative     92\n",
      "Neutral     453\n",
      "Positive    155\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with aave and temperature 1.0\n",
      "Negative     98\n",
      "Neutral     443\n",
      "Positive    159\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with sae and temperature 1.2\n",
      "Negative     92\n",
      "Neutral     448\n",
      "Positive    160\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with aave and temperature 1.2\n",
      "Negative     95\n",
      "Neutral     467\n",
      "Positive    138\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with sae and temperature 1.5\n",
      "Negative    109\n",
      "Neutral     431\n",
      "Positive    160\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with aave and temperature 1.5\n",
      "Negative    107\n",
      "Neutral     430\n",
      "Positive    163\n",
      "Name: 1, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('SAE First Segment')\n",
    "print(sae_first_pd.iloc[:, 1].value_counts().sort_index())\n",
    "print()\n",
    "print('SAE Second Segment')\n",
    "print(sae_second_pd.iloc[:, 1].value_counts().sort_index())\n",
    "print()\n",
    "print('AAVE First Segment')\n",
    "print(aave_first_pd.iloc[:, 1].value_counts().sort_index())\n",
    "print()\n",
    "print('AAVE Second Segment')\n",
    "print(aave_second_pd.iloc[:, 1].value_counts().sort_index())\n",
    "print()\n",
    "\n",
    "for t in temp:\n",
    "    for d in dialects:\n",
    "        print(f'Generation with {d} and temperature {t}')\n",
    "        sae_gen_pd = pd.read_csv('runs/05 Caleb/VADER/temp=' + str(t) + '/' + str(d) + '_gen_txt_sentimental_analysis.csv', header=None)\n",
    "        print(sae_gen_pd.iloc[:, 1].value_counts().sort_index())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Text Blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def textblob_score(sentence):\n",
    "    result = TextBlob(sentence)\n",
    "    if result.sentiment.polarity == 0:\n",
    "        return \"Neutral\"\n",
    "    elif result.sentiment.polarity > 0:\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [0.1, 0.5, 0.7, 1.0, 1.2, 1.5]\n",
    "dialects = ['sae', 'aave']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 3068.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 2880.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 2903.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 2844.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 2891.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 2885.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 2810.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 2570.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 2670.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 2448.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 2755.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 2640.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for t in temp:\n",
    "    for d in dialects:\n",
    "        print(f'starting analyzation on dialect: {d}, temperature: {t}')\n",
    "        df = pd.read_csv('runs/05 Caleb/Generation/half/temp=' + str(t) + '/' + str(d) + '_gen_txt.csv')\n",
    "        with open('runs/05 Caleb/TextBlob/temp=' + str(t) + '/' + str(d) + '_gen_txt_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for i, txt in enumerate(tqdm(df.gen)):\n",
    "                results = textblob_score(txt[2:-2])\n",
    "                writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sae; prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 2681.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sae; prompt_cont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 2380.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aave; prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 3024.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aave; prompt_cont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 2388.53it/s]\n"
     ]
    }
   ],
   "source": [
    "for d in ['sae', 'aave']:\n",
    "    for col in ['prompt', 'prompt_cont']:\n",
    "        print(f'{d}; {col}')\n",
    "        file_name = 'second' if col == 'prompt_cont' else 'first'\n",
    "        df = pd.read_csv('runs/05 Caleb/Generation/half/temp=0.1/' + str(d) + '_gen_txt.csv')\n",
    "        with open('runs/05 Caleb/TextBlob/' + d + '_' + file_name + '_seg_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for i, txt in enumerate(tqdm(df[col])):\n",
    "                results = textblob_score(txt[2:-2])\n",
    "                writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_first_pd = pd.read_csv(\"runs/05 Caleb/TextBlob/sae_first_seg_sentimental_analysis.csv\", header=None)\n",
    "sae_second_pd = pd.read_csv(\"runs/05 Caleb/TextBlob/sae_second_seg_sentimental_analysis.csv\", header=None)\n",
    "aave_first_pd = pd.read_csv(\"runs/05 Caleb/TextBlob/aave_first_seg_sentimental_analysis.csv\", header=None)\n",
    "aave_second_pd = pd.read_csv(\"runs/05 Caleb/TextBlob/aave_second_seg_sentimental_analysis.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE First Segment\n",
      "Negative     72\n",
      "Neutral     433\n",
      "Positive    195\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "SAE Second Segment\n",
      "Negative    105\n",
      "Neutral     419\n",
      "Positive    176\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "AAVE First Segment\n",
      "Negative     70\n",
      "Neutral     440\n",
      "Positive    190\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "AAVE Second Segment\n",
      "Negative     96\n",
      "Neutral     416\n",
      "Positive    188\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with sae and temperature 0.1\n",
      "Negative     86\n",
      "Neutral     451\n",
      "Positive    163\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with aave and temperature 0.1\n",
      "Negative     84\n",
      "Neutral     441\n",
      "Positive    175\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with sae and temperature 0.5\n",
      "Negative     98\n",
      "Neutral     414\n",
      "Positive    188\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with aave and temperature 0.5\n",
      "Negative     77\n",
      "Neutral     438\n",
      "Positive    185\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with sae and temperature 0.7\n",
      "Negative     75\n",
      "Neutral     426\n",
      "Positive    199\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with aave and temperature 0.7\n",
      "Negative     85\n",
      "Neutral     447\n",
      "Positive    168\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with sae and temperature 1.0\n",
      "Negative     81\n",
      "Neutral     429\n",
      "Positive    190\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with aave and temperature 1.0\n",
      "Negative     69\n",
      "Neutral     439\n",
      "Positive    192\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with sae and temperature 1.2\n",
      "Negative     78\n",
      "Neutral     414\n",
      "Positive    208\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with aave and temperature 1.2\n",
      "Negative     93\n",
      "Neutral     430\n",
      "Positive    177\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with sae and temperature 1.5\n",
      "Negative     83\n",
      "Neutral     418\n",
      "Positive    199\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "Generation with aave and temperature 1.5\n",
      "Negative     77\n",
      "Neutral     438\n",
      "Positive    185\n",
      "Name: 1, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('SAE First Segment')\n",
    "print(sae_first_pd.iloc[:, 1].value_counts().sort_index())\n",
    "print()\n",
    "print('SAE Second Segment')\n",
    "print(sae_second_pd.iloc[:, 1].value_counts().sort_index())\n",
    "print()\n",
    "print('AAVE First Segment')\n",
    "print(aave_first_pd.iloc[:, 1].value_counts().sort_index())\n",
    "print()\n",
    "print('AAVE Second Segment')\n",
    "print(aave_second_pd.iloc[:, 1].value_counts().sort_index())\n",
    "print()\n",
    "\n",
    "for t in temp:\n",
    "    for d in dialects:\n",
    "        print(f'Generation with {d} and temperature {t}')\n",
    "        sae_gen_pd = pd.read_csv('runs/05 Caleb/TextBlob/temp=' + str(t) + '/' + str(d) + '_gen_txt_sentimental_analysis.csv', header=None)\n",
    "        print(sae_gen_pd.iloc[:, 1].value_counts().sort_index())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"runs/03 EMNLP SAE-AAVE Pairs/sae_gen_txt.csv\")\n",
    "# with open('runs/03 EMNLP SAE-AAVE Pairs/TextBlob/sae_gen_txt_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     for i, txt in enumerate(tq.tqdm(df.txt)):\n",
    "#         results = textblob_score(txt)\n",
    "#         writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPDmhOJdK8knUJB/yVl90hK",
   "collapsed_sections": [],
   "name": "BERT Dialect Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "231e2839a05f4a6593ec4c5d88e8a788": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e586e8dda6c465ebdd51b0d2433d51f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_80785cc1ab5e4a4a8e6ae01cfd8be7d7",
       "IPY_MODEL_83f2f483822a4354ba913dd96ca8be2c",
       "IPY_MODEL_fa3b9a40dc9943a18a838c6c0e546e89"
      ],
      "layout": "IPY_MODEL_231e2839a05f4a6593ec4c5d88e8a788"
     }
    },
    "80785cc1ab5e4a4a8e6ae01cfd8be7d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fca3a2fbff874386ae0e35b4efa3a922",
      "placeholder": "​",
      "style": "IPY_MODEL_96494ddfd9aa4f9eb7f8f9823d382fe3",
      "value": "Downloading: 100%"
     }
    },
    "83f2f483822a4354ba913dd96ca8be2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91c7ea6883d84937ada56f387fb98cbd",
      "max": 435779157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d9ecb8eb875a45978569b34eef0c3da6",
      "value": 435779157
     }
    },
    "91c7ea6883d84937ada56f387fb98cbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96494ddfd9aa4f9eb7f8f9823d382fe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d9ecb8eb875a45978569b34eef0c3da6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "de3a5ace7bad4963954ad0b9088a4149": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa3b9a40dc9943a18a838c6c0e546e89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de3a5ace7bad4963954ad0b9088a4149",
      "placeholder": "​",
      "style": "IPY_MODEL_fc3029839bb640f0a4198a5c0beabd8e",
      "value": " 436M/436M [00:10&lt;00:00, 36.3MB/s]"
     }
    },
    "fc3029839bb640f0a4198a5c0beabd8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fca3a2fbff874386ae0e35b4efa3a922": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

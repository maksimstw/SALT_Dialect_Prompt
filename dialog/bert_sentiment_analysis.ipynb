{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7068,
     "status": "ok",
     "timestamp": 1630505480342,
     "user": {
      "displayName": "Maksim STW",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxlsxJPsP-vnUHqOGVOd2IwzlsoHIBvoM27xTB=s64",
      "userId": "15228803154242880172"
     },
     "user_tz": 240
    },
    "id": "LPrt3Gw6siZn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'runs/21/dataset/dialogpt/all/dailydialog_dataset_all.csv'\n",
    "gen_path = 'runs/21/gen/dialogpt/all/dailydialog_dataset_all_gen.csv'\n",
    "sent_path = 'runs/21/sent/dialogpt/all/dailydialog_dataset_all_sent.csv'\n",
    "final_path = 'runs/21/concat/dialogpt/all/dailydialog_dataset_all_concat.csv'\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "df_gen = pd.read_csv(gen_path)\n",
    "df['gen_aave'] = df_gen['aave_gen']\n",
    "df['gen_sae'] = df_gen['sae_gen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>history</th>\n",
       "      <th>groundtruth</th>\n",
       "      <th>history_aave</th>\n",
       "      <th>history_html</th>\n",
       "      <th>num_aave_fts</th>\n",
       "      <th>groundtruth_aave</th>\n",
       "      <th>gen_sae</th>\n",
       "      <th>gen_aave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Complete the following conversation.\\nA: So he...</td>\n",
       "      <td>That's never been proven&lt;|endoftext|&gt;</td>\n",
       "      <td>Complete the following conversation.\\nA: So he...</td>\n",
       "      <td>So he &lt;a href='got' title='1'&gt;&lt;mark&gt;has&lt;/mark&gt;...</td>\n",
       "      <td>6</td>\n",
       "      <td>Dat's never ain't no proven&lt;|endoftext|</td>\n",
       "      <td>\\n\\nI'm sorry to hear that he's been giving yo...</td>\n",
       "      <td>You right. He didn't.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Complete the following conversation.\\nA: Katar...</td>\n",
       "      <td>I still maintain that he kicked himself in the...</td>\n",
       "      <td>Complete the following conversation.\\nA: Katar...</td>\n",
       "      <td>Katarina Stratford.  My, my.  You've been terr...</td>\n",
       "      <td>6</td>\n",
       "      <td>I still maintain that he kicked hisself in the...</td>\n",
       "      <td>\\n\\nI'm glad to hear Bobby's operation went well.</td>\n",
       "      <td>\\n\\nI'm not interested.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Complete the following conversation.\\nA: How f...</td>\n",
       "      <td>I am afraid this is not the worst news.&lt;|endof...</td>\n",
       "      <td>Complete the following conversation.\\nA: How f...</td>\n",
       "      <td>How far from here?&lt;|endoftext|&gt;I &lt;a href='nega...</td>\n",
       "      <td>7</td>\n",
       "      <td>I am afraid dis ain't da worst news.&lt;|endoftext|&gt;</td>\n",
       "      <td>You found it?  You're the captain?\\n\\nA: How ...</td>\n",
       "      <td>You is one smart woman, Missus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Complete the following conversation.\\nA: May I...</td>\n",
       "      <td>A woman?&lt;|endoftext|&gt;</td>\n",
       "      <td>Complete the following conversation.\\nA: May I...</td>\n",
       "      <td>May I speak freely?&lt;|endoftext|&gt;You show no in...</td>\n",
       "      <td>7</td>\n",
       "      <td>A woman?&lt;|endoftext|&gt;</td>\n",
       "      <td>You make me sound like a superhero.\\nA: You a...</td>\n",
       "      <td>You see a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Complete the following conversation.\\nA: I cam...</td>\n",
       "      <td>I'm just trying to find out who you are.&lt;|endo...</td>\n",
       "      <td>Complete the following conversation.\\nA: I cam...</td>\n",
       "      <td>I came here.  I had no money.  I knew no one. ...</td>\n",
       "      <td>8</td>\n",
       "      <td>I'm jus tryna find out who yuu r.&lt;|endoftext|&gt;</td>\n",
       "      <td>I was just wondering if you had ever been a p...</td>\n",
       "      <td>I'm just sayin, you've never been a prostitut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>Complete the following conversation.\\nA: Oh! O...</td>\n",
       "      <td>This?&lt;|endoftext|&gt;</td>\n",
       "      <td>Complete the following conversation.\\nA: Oh! O...</td>\n",
       "      <td>Oh! Oh, it &lt;a href='uninflect' title='1'&gt;&lt;mark...</td>\n",
       "      <td>6</td>\n",
       "      <td>Dis?&lt;|endoftext|&gt;</td>\n",
       "      <td>What is it, Professor?\\n\\nA: This is my Mirac...</td>\n",
       "      <td>What is it, Scarecrow?\\n\\nA: It's a heart, Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>Complete the following conversation.\\nA: Now l...</td>\n",
       "      <td>Oh, Hunk, you just won't listen, that's all.&lt;|...</td>\n",
       "      <td>Complete the following conversation.\\nA: Now l...</td>\n",
       "      <td>Now lookit, Dorothy, you ain't using your head...</td>\n",
       "      <td>6</td>\n",
       "      <td>Oh, Hunk, yu jus won't listen, dat's all.&lt;|end...</td>\n",
       "      <td>That's a good idea.  I'll go home a different...</td>\n",
       "      <td>All right, Auntie Em.  I'll do just what you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>Complete the following conversation.\\nA: Sphin...</td>\n",
       "      <td>Oh sweetheart, just a quick one.&lt;|endoftext|&gt;</td>\n",
       "      <td>Complete the following conversation.\\nA: Sphin...</td>\n",
       "      <td>Sphinx brand.  When I got out of weapons desig...</td>\n",
       "      <td>6</td>\n",
       "      <td>Oh sweetheart, jus a quick one.&lt;|endoftext|&gt;</td>\n",
       "      <td>I'm sorry.  I thought we were just talking.\\n...</td>\n",
       "      <td>\\n\\nI'm sorry, Adrian. I won't ask any more qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>Complete the following conversation.\\nA: To us...</td>\n",
       "      <td>How you gonna do that with government and rule...</td>\n",
       "      <td>Complete the following conversation.\\nA: To us...</td>\n",
       "      <td>To us it &lt;a href='uninflect' title='1'&gt;&lt;mark&gt;m...</td>\n",
       "      <td>9</td>\n",
       "      <td>How you gonna do dat with government and rule ...</td>\n",
       "      <td>Yeah, I hear you. But isn't that just chaos?\\...</td>\n",
       "      <td>But then there's no order and people just do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Complete the following conversation.\\nA: Corre...</td>\n",
       "      <td>So where do you think he's planning this large...</td>\n",
       "      <td>Complete the following conversation.\\nA: Corre...</td>\n",
       "      <td>Correct...  Apparently, Adamantium &lt;a href='dr...</td>\n",
       "      <td>12</td>\n",
       "      <td>Soo where yu think he's planning dis larger de...</td>\n",
       "      <td>So what do we do?\\n\\nA: We need to find a way...</td>\n",
       "      <td>So what do we do?\\n\\nA: We have to stop him b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>972 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               history  \\\n",
       "0    Complete the following conversation.\\nA: So he...   \n",
       "1    Complete the following conversation.\\nA: Katar...   \n",
       "2    Complete the following conversation.\\nA: How f...   \n",
       "3    Complete the following conversation.\\nA: May I...   \n",
       "4    Complete the following conversation.\\nA: I cam...   \n",
       "..                                                 ...   \n",
       "967  Complete the following conversation.\\nA: Oh! O...   \n",
       "968  Complete the following conversation.\\nA: Now l...   \n",
       "969  Complete the following conversation.\\nA: Sphin...   \n",
       "970  Complete the following conversation.\\nA: To us...   \n",
       "971  Complete the following conversation.\\nA: Corre...   \n",
       "\n",
       "                                           groundtruth  \\\n",
       "0                That's never been proven<|endoftext|>   \n",
       "1    I still maintain that he kicked himself in the...   \n",
       "2    I am afraid this is not the worst news.<|endof...   \n",
       "3                                A woman?<|endoftext|>   \n",
       "4    I'm just trying to find out who you are.<|endo...   \n",
       "..                                                 ...   \n",
       "967                                 This?<|endoftext|>   \n",
       "968  Oh, Hunk, you just won't listen, that's all.<|...   \n",
       "969      Oh sweetheart, just a quick one.<|endoftext|>   \n",
       "970  How you gonna do that with government and rule...   \n",
       "971  So where do you think he's planning this large...   \n",
       "\n",
       "                                          history_aave  \\\n",
       "0    Complete the following conversation.\\nA: So he...   \n",
       "1    Complete the following conversation.\\nA: Katar...   \n",
       "2    Complete the following conversation.\\nA: How f...   \n",
       "3    Complete the following conversation.\\nA: May I...   \n",
       "4    Complete the following conversation.\\nA: I cam...   \n",
       "..                                                 ...   \n",
       "967  Complete the following conversation.\\nA: Oh! O...   \n",
       "968  Complete the following conversation.\\nA: Now l...   \n",
       "969  Complete the following conversation.\\nA: Sphin...   \n",
       "970  Complete the following conversation.\\nA: To us...   \n",
       "971  Complete the following conversation.\\nA: Corre...   \n",
       "\n",
       "                                          history_html  num_aave_fts  \\\n",
       "0    So he <a href='got' title='1'><mark>has</mark>...             6   \n",
       "1    Katarina Stratford.  My, my.  You've been terr...             6   \n",
       "2    How far from here?<|endoftext|>I <a href='nega...             7   \n",
       "3    May I speak freely?<|endoftext|>You show no in...             7   \n",
       "4    I came here.  I had no money.  I knew no one. ...             8   \n",
       "..                                                 ...           ...   \n",
       "967  Oh! Oh, it <a href='uninflect' title='1'><mark...             6   \n",
       "968  Now lookit, Dorothy, you ain't using your head...             6   \n",
       "969  Sphinx brand.  When I got out of weapons desig...             6   \n",
       "970  To us it <a href='uninflect' title='1'><mark>m...             9   \n",
       "971  Correct...  Apparently, Adamantium <a href='dr...            12   \n",
       "\n",
       "                                      groundtruth_aave  \\\n",
       "0              Dat's never ain't no proven<|endoftext|   \n",
       "1    I still maintain that he kicked hisself in the...   \n",
       "2    I am afraid dis ain't da worst news.<|endoftext|>   \n",
       "3                                A woman?<|endoftext|>   \n",
       "4       I'm jus tryna find out who yuu r.<|endoftext|>   \n",
       "..                                                 ...   \n",
       "967                                  Dis?<|endoftext|>   \n",
       "968  Oh, Hunk, yu jus won't listen, dat's all.<|end...   \n",
       "969       Oh sweetheart, jus a quick one.<|endoftext|>   \n",
       "970  How you gonna do dat with government and rule ...   \n",
       "971  Soo where yu think he's planning dis larger de...   \n",
       "\n",
       "                                               gen_sae  \\\n",
       "0    \\n\\nI'm sorry to hear that he's been giving yo...   \n",
       "1    \\n\\nI'm glad to hear Bobby's operation went well.   \n",
       "2     You found it?  You're the captain?\\n\\nA: How ...   \n",
       "3     You make me sound like a superhero.\\nA: You a...   \n",
       "4     I was just wondering if you had ever been a p...   \n",
       "..                                                 ...   \n",
       "967   What is it, Professor?\\n\\nA: This is my Mirac...   \n",
       "968   That's a good idea.  I'll go home a different...   \n",
       "969   I'm sorry.  I thought we were just talking.\\n...   \n",
       "970   Yeah, I hear you. But isn't that just chaos?\\...   \n",
       "971   So what do we do?\\n\\nA: We need to find a way...   \n",
       "\n",
       "                                              gen_aave  \n",
       "0                                You right. He didn't.  \n",
       "1                              \\n\\nI'm not interested.  \n",
       "2                      You is one smart woman, Missus.  \n",
       "3                                       You see a lot.  \n",
       "4     I'm just sayin, you've never been a prostitut...  \n",
       "..                                                 ...  \n",
       "967   What is it, Scarecrow?\\n\\nA: It's a heart, Do...  \n",
       "968   All right, Auntie Em.  I'll do just what you ...  \n",
       "969  \\n\\nI'm sorry, Adrian. I won't ask any more qu...  \n",
       "970   But then there's no order and people just do ...  \n",
       "971   So what do we do?\\n\\nA: We have to stop him b...  \n",
       "\n",
       "[972 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('runs/21/gen/gpt3/gpt3_cornell_movie_gen.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gt(s):\n",
    "    return s.replace('<|endoftext|>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['groundtruth'] = df['groundtruth'].apply(clean_gt)\n",
    "df['groundtruth_aave'] = df['groundtruth_aave'].apply(clean_gt)\n",
    "\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model: siebert/sentiment-roberta-large-english\n"
     ]
    }
   ],
   "source": [
    "model_name = 'roberta_large'\n",
    "\n",
    "cols = ['history', 'history_aave', 'sae_gen', 'aave_gen']\n",
    "\n",
    "if model_name == 'distilbert':\n",
    "    model = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "elif model_name == 'roberta_base':\n",
    "    model = 'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "elif model_name == 'roberta_large':\n",
    "    model = 'siebert/sentiment-roberta-large-english'\n",
    "else:\n",
    "    raise Exception('MODEL NOT FOUND!!!')\n",
    "\n",
    "print(f'using model: {model}')\n",
    "classifier = pipeline('sentiment-analysis', device=4, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 972/972 [00:07<00:00, 131.24it/s]\n",
      "100%|██████████| 972/972 [00:06<00:00, 142.49it/s]\n",
      "100%|██████████| 972/972 [00:15<00:00, 63.45it/s]\n",
      "100%|██████████| 972/972 [00:15<00:00, 63.80it/s]\n"
     ]
    }
   ],
   "source": [
    "gt_list = []\n",
    "gt_aave_list = []\n",
    "gen_list = []\n",
    "gen_aave_list = []\n",
    "for score in tqdm(classifier(KeyDataset(dataset, 'groundtruth'), batch_size=16, truncation='only_first'), total=len(dataset)):\n",
    "    gt_list.append(score['label'])\n",
    "for score in tqdm(classifier(KeyDataset(dataset, 'groundtruth_aave'), batch_size=16, truncation='only_first'), total=len(dataset)):\n",
    "    gt_aave_list.append(score['label'])\n",
    "for score in tqdm(classifier(KeyDataset(dataset, 'gen_sae'), batch_size=16, truncation='only_first'), total=len(dataset)):\n",
    "    gen_list.append(score['label'])\n",
    "for score in tqdm(classifier(KeyDataset(dataset, 'gen_aave'), batch_size=16, truncation='only_first'), total=len(dataset)):\n",
    "    gen_aave_list.append(score['label'])    \n",
    "df['gt_sent'] = gt_list\n",
    "df['gt_aave_sent'] = gt_aave_list\n",
    "df['gen_sent'] = gen_list\n",
    "df['gen_aave_sent'] = gen_aave_list\n",
    "\n",
    "df.to_csv('runs/21/concat/gpt3/cornell_movie_dataset_all_concat.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# function to print sentiments\n",
    "# of the sentence.\n",
    "def sentiment_scores(sentence):\n",
    " \n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    # object gives a sentiment dictionary.\n",
    "    # which contains pos, neg, neu, and compound scores.\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    " \n",
    "    # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        return \"Positive\"\n",
    " \n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        return \"Negative\"\n",
    " \n",
    "    else :\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Analysis on Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [0.1, 0.5, 0.7, 1.0, 1.2, 1.5]\n",
    "dialects = ['sae', 'aave']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 137.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 140.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 138.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 139.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 141.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 136.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 142.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 136.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 137.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 140.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 434/434 [00:03<00:00, 142.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 420/420 [00:03<00:00, 136.71it/s]\n"
     ]
    }
   ],
   "source": [
    "for t in temp:\n",
    "    for d in dialects:\n",
    "        print(f'starting analyzation on dialect: {d}, temperature: {t}')\n",
    "        df = pd.read_csv('runs/' + output_path +'/Generation/temp=' + str(t) + '/' + d + '_gen_txt.csv')\n",
    "        with open('runs/' + output_path +'/VADER/temp=' + str(t) + '/' + d + '_gen_txt_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for i, txt in enumerate(tqdm(df.gen)):\n",
    "                results = sentiment_scores(txt)\n",
    "                writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Analysis on Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sae; prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 137.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sae; prompt_cont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 139.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aave; prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 134.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aave; prompt_cont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 492/492 [00:03<00:00, 127.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for d in ['sae', 'aave']:\n",
    "    for col in ['prompt', 'prompt_cont']:\n",
    "        print(f'{d}; {col}')\n",
    "        df = pd.read_csv('runs/' + output_path +'/Generation/temp=0.1/' + d + '_gen_txt.csv')\n",
    "        with open('runs/' + output_path +'/VADER/' + d + '_' + col + '_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for i, txt in enumerate(tqdm(df[col])):\n",
    "                results = sentiment_scores(txt[2:-2])\n",
    "                writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"runs/03 EMNLP SAE-AAVE Pairs/sae_samples.tsv\", sep=\"\\t\")\n",
    "# with open('runs/03 EMNLP SAE-AAVE Pairs/VADER/sae_second_seg_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     for i, txt in enumerate(tq.tqdm(df.second_seg)):\n",
    "#         results = sentiment_scores(txt)\n",
    "#         writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER, sae, prompt\n",
      "Negative     78\n",
      "Neutral     299\n",
      "Positive    115\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "VADER, sae, prompt_cont\n",
      "Negative    103\n",
      "Neutral     294\n",
      "Positive     95\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "VADER, aave, prompt\n",
      "Negative     77\n",
      "Neutral     300\n",
      "Positive    115\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "VADER, aave, prompt_cont\n",
      "Negative     97\n",
      "Neutral     296\n",
      "Positive     99\n",
      "Name: 1, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('stats.csv', 'w', encoding='utf-8', newline='')\n",
    "for d in dialects:\n",
    "    for col in ['prompt', 'prompt_cont']:\n",
    "        df = pd.read_csv('runs/' + output_path +'/VADER/' + d + '_' + col + '_sentimental_analysis.csv', header=None)\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print(f'VADER, {d}, {col}')\n",
    "        print(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: VADER; generation: sae; temperature 0.1\n",
      "Negative     62\n",
      "Neutral     341\n",
      "Positive     89\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: aave; temperature 0.1\n",
      "Negative     80\n",
      "Neutral     326\n",
      "Positive     86\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: sae; temperature 0.5\n",
      "Negative     45\n",
      "Neutral     358\n",
      "Positive     89\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: aave; temperature 0.5\n",
      "Negative     60\n",
      "Neutral     319\n",
      "Positive    113\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: sae; temperature 0.7\n",
      "Negative     59\n",
      "Neutral     335\n",
      "Positive     98\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: aave; temperature 0.7\n",
      "Negative     63\n",
      "Neutral     322\n",
      "Positive    107\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: sae; temperature 1.0\n",
      "Negative     48\n",
      "Neutral     337\n",
      "Positive    107\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: aave; temperature 1.0\n",
      "Negative     70\n",
      "Neutral     327\n",
      "Positive     95\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: sae; temperature 1.2\n",
      "Negative     53\n",
      "Neutral     334\n",
      "Positive    105\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: aave; temperature 1.2\n",
      "Negative     61\n",
      "Neutral     328\n",
      "Positive    103\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: sae; temperature 1.5\n",
      "Negative     48\n",
      "Neutral     299\n",
      "Positive     87\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: VADER; generation: aave; temperature 1.5\n",
      "Negative     58\n",
      "Neutral     275\n",
      "Positive     87\n",
      "Name: 1, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('stats.csv', 'w', encoding='utf-8', newline='')\n",
    "for t in temp:\n",
    "    for d in dialects:\n",
    "        df = pd.read_csv('runs/' + output_path +'/VADER/temp=' + str(t) + '/' + str(d) + '_gen_txt_sentimental_analysis.csv', header=None)\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print(f'model: VADER; generation: {d}; temperature {t}')\n",
    "        print(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run Text Blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Blob Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def textblob_score(sentence):\n",
    "    result = TextBlob(sentence)\n",
    "    if result.sentiment.polarity == 0:\n",
    "        return \"Neutral\"\n",
    "    elif result.sentiment.polarity > 0:\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [0.1, 0.5, 0.7, 1.0, 1.2, 1.5]\n",
    "dialects = ['sae', 'aave']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Analysis on Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 4729.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8198.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8337.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8198.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8337.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8337.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8337.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8337.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8480.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 8337.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: sae, temperature: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 434/434 [00:00<00:00, 8344.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting analyzation on dialect: aave, temperature: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 420/420 [00:00<00:00, 7922.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for t in temp:\n",
    "    for d in dialects:\n",
    "        print(f'starting analyzation on dialect: {d}, temperature: {t}')\n",
    "        df = pd.read_csv('runs/' + output_path +'/Generation/temp=' + str(t) + '/' + d + '_gen_txt.csv')\n",
    "        with open('runs/' + output_path +'/TextBlob/temp=' + str(t) + '/' + d + '_gen_txt_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for i, txt in enumerate(tqdm(df.gen)):\n",
    "                results = textblob_score(txt)\n",
    "                writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Analysis on Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob, sae; prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 7026.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob, sae; prompt_cont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 7807.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob, aave; prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 7567.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob, aave; prompt_cont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 492/492 [00:00<00:00, 7567.70it/s]\n"
     ]
    }
   ],
   "source": [
    "for d in ['sae', 'aave']:\n",
    "    for col in ['prompt', 'prompt_cont']:\n",
    "        print(f'TextBlob, {d}; {col}')\n",
    "        df = pd.read_csv('runs/' + output_path +'/Generation/temp=0.1/' + d + '_gen_txt.csv')\n",
    "        with open('runs/' + output_path +'/TextBlob/' + d + '_' + col + '_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for i, txt in enumerate(tqdm(df[col])):\n",
    "                results = textblob_score(txt[2:-2])\n",
    "                writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob Gen, sae, prompt\n",
      "Negative     57\n",
      "Neutral     306\n",
      "Positive    129\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "TextBlob Gen, sae, prompt_cont\n",
      "Negative     67\n",
      "Neutral     309\n",
      "Positive    116\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "TextBlob Gen, aave, prompt\n",
      "Negative     55\n",
      "Neutral     318\n",
      "Positive    119\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "TextBlob Gen, aave, prompt_cont\n",
      "Negative     49\n",
      "Neutral     324\n",
      "Positive    119\n",
      "Name: 1, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('stats.csv', 'w', encoding='utf-8', newline='')\n",
    "for d in ['sae', 'aave']:\n",
    "    for col in ['prompt', 'prompt_cont']:\n",
    "        df = pd.read_csv('runs/' + output_path +'/TextBlob/' + d + '_' + col + '_sentimental_analysis.csv', header=None)\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print(f'TextBlob Gen, {d}, {col}')\n",
    "        print(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: TextBlob; generation: sae; temperature 0.1\n",
      "Negative     59\n",
      "Neutral     345\n",
      "Positive     88\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: aave; temperature 0.1\n",
      "Negative     67\n",
      "Neutral     314\n",
      "Positive    111\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: sae; temperature 0.5\n",
      "Negative     48\n",
      "Neutral     329\n",
      "Positive    115\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: aave; temperature 0.5\n",
      "Negative     63\n",
      "Neutral     312\n",
      "Positive    117\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: sae; temperature 0.7\n",
      "Negative     56\n",
      "Neutral     325\n",
      "Positive    111\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: aave; temperature 0.7\n",
      "Negative     48\n",
      "Neutral     320\n",
      "Positive    124\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: sae; temperature 1.0\n",
      "Negative     56\n",
      "Neutral     331\n",
      "Positive    105\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: aave; temperature 1.0\n",
      "Negative     52\n",
      "Neutral     314\n",
      "Positive    126\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: sae; temperature 1.2\n",
      "Negative     46\n",
      "Neutral     334\n",
      "Positive    112\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: aave; temperature 1.2\n",
      "Negative     50\n",
      "Neutral     317\n",
      "Positive    125\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: sae; temperature 1.5\n",
      "Negative     50\n",
      "Neutral     269\n",
      "Positive    115\n",
      "Name: 1, dtype: int64\n",
      "\n",
      "model: TextBlob; generation: aave; temperature 1.5\n",
      "Negative     44\n",
      "Neutral     281\n",
      "Positive     95\n",
      "Name: 1, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('stats.csv', 'w', encoding='utf-8', newline='')\n",
    "for t in temp:\n",
    "    for d in dialects:\n",
    "        print(f'model: TextBlob; generation: {d}; temperature {t}')\n",
    "        df = pd.read_csv('runs/' + output_path +'/TextBlob/temp=' + str(t) + '/' + str(d) + '_gen_txt_sentimental_analysis.csv', header=None)\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print(df.iloc[:, 1].value_counts().sort_index())\n",
    "        print()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"runs/03 EMNLP SAE-AAVE Pairs/sae_gen_txt.csv\")\n",
    "# with open('runs/03 EMNLP SAE-AAVE Pairs/TextBlob/sae_gen_txt_sentimental_analysis.csv', 'a', encoding=\"utf-8\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     for i, txt in enumerate(tq.tqdm(df.txt)):\n",
    "#         results = textblob_score(txt)\n",
    "#         writer.writerow([i, results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPDmhOJdK8knUJB/yVl90hK",
   "collapsed_sections": [],
   "name": "BERT Dialect Classification.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "2e11e5a522e080512818b9bf84dbbd443475dd70c5375019780e8dfd28d97bce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('CS_4650_Proj': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "231e2839a05f4a6593ec4c5d88e8a788": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e586e8dda6c465ebdd51b0d2433d51f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_80785cc1ab5e4a4a8e6ae01cfd8be7d7",
       "IPY_MODEL_83f2f483822a4354ba913dd96ca8be2c",
       "IPY_MODEL_fa3b9a40dc9943a18a838c6c0e546e89"
      ],
      "layout": "IPY_MODEL_231e2839a05f4a6593ec4c5d88e8a788"
     }
    },
    "80785cc1ab5e4a4a8e6ae01cfd8be7d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fca3a2fbff874386ae0e35b4efa3a922",
      "placeholder": "​",
      "style": "IPY_MODEL_96494ddfd9aa4f9eb7f8f9823d382fe3",
      "value": "Downloading: 100%"
     }
    },
    "83f2f483822a4354ba913dd96ca8be2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91c7ea6883d84937ada56f387fb98cbd",
      "max": 435779157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d9ecb8eb875a45978569b34eef0c3da6",
      "value": 435779157
     }
    },
    "91c7ea6883d84937ada56f387fb98cbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96494ddfd9aa4f9eb7f8f9823d382fe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d9ecb8eb875a45978569b34eef0c3da6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "de3a5ace7bad4963954ad0b9088a4149": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa3b9a40dc9943a18a838c6c0e546e89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de3a5ace7bad4963954ad0b9088a4149",
      "placeholder": "​",
      "style": "IPY_MODEL_fc3029839bb640f0a4198a5c0beabd8e",
      "value": " 436M/436M [00:10&lt;00:00, 36.3MB/s]"
     }
    },
    "fc3029839bb640f0a4198a5c0beabd8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fca3a2fbff874386ae0e35b4efa3a922": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
